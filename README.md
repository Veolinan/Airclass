#AirClass â€“ Touchless Interactive Learning for Everyone

AirClass is an **AI-powered, gesture-controlled educational platform** designed to make learning **inclusive, engaging, and accessible**, especially for **physically challenged learners**.  
It uses **computer vision, hand tracking, and gesture-based interaction** to create a fully **touchless classroom experience** where learners interact with lessons by moving their hands in the air.  

---

## âœ¨ Key Features

- ğŸ¥ **Camera Overlay UI** â€“ Live camera feed with interactive buttons and elements drawn on top.  
- âœ‹ **Hand Tracking & Gesture Control** â€“ Pinch, swipe, and hover to interact with lessons.  
- ğŸ“š **Learning Modules**
  - **Shapes & Colors** â€“ Learn to recognize, identify, and interact with different shapes and colors.  
  - **Numbers** â€“ Counting, addition, subtraction, multiplication, division, odd/even, fill-in-the-missing, and tracing.  
  - **Spellings** â€“ Interactive spelling practice with letter selection, hints, lives, and pronunciation.  
  - **Drawing** â€“ Draw shapes and numbers using hand gestures.  
- ğŸ”Š **Audio-Visual Feedback** â€“ Sounds, animations, and on-screen prompts for engagement.  
- ğŸ¨ **Nickelodeon-style UI** â€“ Flashy, colorful, and kid-friendly interface.  
- â™¿ **Inclusive Design** â€“ Built for physically challenged learners with **hands-free interaction**.  

---

## ğŸ“‚ Project Structure

```
AirClass/
â”‚
â”œâ”€â”€ main.py              # Main entry point (menu + shared resources)
â”œâ”€â”€ graphics.py          # Rendering utilities (buttons, overlays, UI elements)
â”œâ”€â”€ hand_tracker.py      # Mediapipe-based hand tracking
â”‚
â”œâ”€â”€ modules/             # All learning modules
â”‚   â”œâ”€â”€ shapes_colors.py
â”‚   â”œâ”€â”€ numbers.py
â”‚   â”œâ”€â”€ spellings.py
â”‚   â””â”€â”€ drawing.py
â”‚
â”œâ”€â”€ assets/              # Sounds, icons, animations
â”‚   â”œâ”€â”€ sounds/
â”‚   â”œâ”€â”€ icons/
â”‚   â””â”€â”€ tutor/
â”‚
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md            # Documentation
```

---

## ğŸ–¥ï¸ Installation Guide (Windows)

Follow these steps to set up and run AirClass on **Windows**:

### 1. Clone the Repository
```bash
git clone https://github.com/Veolinan/Airclass.git
cd Airclass
```

### 2. Create Virtual Environment
```bash
python -m venv venv
```

### 3. Activate Virtual Environment
```bash
venv\Scriptsctivate
```
You should see `(venv)` before your command prompt.

### 4. Install Dependencies
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 5. Run the Application
```bash
python main.py
```

---

## ğŸ® Usage

Launch `main.py` and use your hand in front of the webcam to interact:

- âœ‹ **Pinch (index + thumb)** to select items  
- â³ **Hover & Hold** on menu buttons to open a module  
- ğŸ”™ **Back button** inside modules to return to main menu  
- ğŸ”Š Follow on-screen **audio + visual prompts**  

---

## ğŸ”§ Dependencies

- OpenCV â€“ Camera & image processing  
- Mediapipe â€“ Hand tracking  
- Pygame â€“ UI, sound, graphics  
- TensorFlow Lite Runtime â€“ For gesture model inference (optional AI integration)  
- All dependencies are listed in `requirements.txt`.  

---

## ğŸŒ Vision & Impact

AirClass is more than a project â€“ itâ€™s a step towards inclusive education.  
By enabling hands-free, gesture-based learning, it ensures that physically challenged learners can participate in interactive lessons without barriers.  

---

## ğŸ¤ Contributing

We welcome contributions!

1. Fork the repo  
2. Create a feature branch  
3. Submit a PR ğŸš€  

---

## ğŸ“œ License

MIT License â€“ free to use, modify, and share.  
